{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.feature import hog\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.ndimage.measurements import label\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import pickle\n",
    "\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliding Window\n",
    "\n",
    "There are at least two ways to implement a sliding window search. Either use a size-fixed window to silde in different scaled images, or use different sized windows to slide in the same image. I tried both methods. However, only the first method is presented. \n",
    "\n",
    "#### Method One (only code)\n",
    "\n",
    "The following function `slide_window()` takes in an image, start and stop positions in both x and y (imagine a bounding box for the entire search region), window size (x and y dimensions), and overlap fraction (also for both x and y). And it returns a list of bounding boxes for the search windows, which will then be passed to draw draw_boxes() function."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def slide_window(img, \n",
    "                 x_start_stop=[None, None], \n",
    "                 y_start_stop=[None, None], \n",
    "                 xy_window=(64, 64), \n",
    "                 xy_overlap=(0.5, 0.5)):\n",
    "    \"\"\"\n",
    "    :param x_start_stop: start and stop positions in x direction\n",
    "    :param y_start_stop: start and stop positions in y direction\n",
    "    :param xy_window: window size (x and y dimensions)\n",
    "    :param xy_overlap: overlap fraction for both x and y\n",
    "    :return: a list of bounding boxes for the search windows, which will then be passed to \n",
    "    `draw_boxes()` function\n",
    "    \"\"\"\n",
    "    \n",
    "    # If x and/or y start/stop positions not defined, set to image size\n",
    "    if x_start_stop[0] == None:\n",
    "        x_start_stop[0] = 0\n",
    "    if x_start_stop[1] == None:\n",
    "        x_start_stop[1] = img.shape[1]\n",
    "    if y_start_stop[0] == None:\n",
    "        y_start_stop[0] = 0\n",
    "    if y_start_stop[1] == None:\n",
    "        y_start_stop[1] = img.shape[0]\n",
    "        \n",
    "    # Compute the span of the region to be searched    \n",
    "    xspan = x_start_stop[1] - x_start_stop[0]\n",
    "    yspan = y_start_stop[1] - y_start_stop[0]\n",
    "    \n",
    "    # Compute the number of pixels per step in x/y\n",
    "    nx_pix_per_step = np.int(xy_window[0]*(1 - xy_overlap[0]))\n",
    "    ny_pix_per_step = np.int(xy_window[1]*(1 - xy_overlap[1]))\n",
    "    \n",
    "    # Compute the number of windows in x/y\n",
    "    nx_buffer = np.int(xy_window[0]*(xy_overlap[0]))\n",
    "    ny_buffer = np.int(xy_window[1]*(xy_overlap[1]))\n",
    "    nx_windows = np.int((xspan-nx_buffer)/nx_pix_per_step) \n",
    "    ny_windows = np.int((yspan-ny_buffer)/ny_pix_per_step) \n",
    "    \n",
    "    # Initialize a list to append window positions to\n",
    "    window_list = []\n",
    "    \n",
    "    # Loop through finding x and y window positions\n",
    "    # Note: you could vectorize this step, but in practice\n",
    "    # you'll be considering windows one by one with your\n",
    "    # classifier, so looping makes sense\n",
    "    for ys in range(ny_windows):\n",
    "        for xs in range(nx_windows):\n",
    "            # Calculate window position\n",
    "            startx = xs*nx_pix_per_step + x_start_stop[0]\n",
    "            endx = startx + xy_window[0]\n",
    "            starty = ys*ny_pix_per_step + y_start_stop[0]\n",
    "            endy = starty + xy_window[1]\n",
    "            # Append window position to list\n",
    "            window_list.append(((startx, starty), (endx, endy)))\n",
    "    # Return the list of windows\n",
    "    return window_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `draw_boxes()` takes an image, a list of bounding boxes, and optional color tuple and line thickness as inputs, then draws boxes in that color on the output."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "def draw_boxes(img, bboxes, color=(0, 0, 255), thick=6):\n",
    "    \"\"\"\n",
    "    :param bboxes: a list of bounding boxes, e.g. the output of `slide_window()`\n",
    "    :param color: color tuple\n",
    "    :param thick: line thickness\n",
    "    :return: draw boxes in that color on the output\n",
    "    \"\"\"\n",
    "    # make a copy of the image\n",
    "    draw_img = np.copy(img)\n",
    "    # draw each bounding box on your image copy using cv2.rectangle()\n",
    "    for b in bboxes:\n",
    "        cv2.rectangle(draw_img, b[0],b[1], color, thick)\n",
    "    # return the image copy with boxes drawn\n",
    "    return draw_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method Two - Part I: Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_color(img, conv='RGB2YCrCb'):\n",
    "    if conv == 'RGB2YCrCb':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "    if conv == 'BGR2YCrCb':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "    if conv == 'RGB2LUV':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2LUV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hog_features(img, \n",
    "                     orient, \n",
    "                     pix_per_cell, \n",
    "                     cell_per_block, \n",
    "                     vis=False, \n",
    "                     feature_vec=True):\n",
    "    \"\"\"\n",
    "    :param orient: the number of orientations. It is specified as an integer and represents\n",
    "        the number of orientation bins that the gradient information will be split up into\n",
    "        in the histogram. Typical values are between 6 and 12 bins.\n",
    "    :param pixels_per_cell: It is a 2-tuple, which specifies the cell size over which each \n",
    "        gradient histogram is computed. \n",
    "    :param cell_per_block: It is a 2-tuple, which specifies the local area over which the \n",
    "        histogram counts in a given cell will be normalized.\n",
    "    :return: HOG features and visualization\n",
    "    \"\"\"\n",
    "    # Call with two outputs if vis==True\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, \n",
    "                                  orientations=orient, \n",
    "                                  pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), \n",
    "                                  transform_sqrt=False, \n",
    "                                  visualise=vis, \n",
    "                                  feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:      \n",
    "        features = hog(img, \n",
    "                       orientations=orient, \n",
    "                       pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), \n",
    "                       transform_sqrt=False, \n",
    "                       visualise=vis, \n",
    "                       feature_vector=feature_vec)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method Two - Part II: Implementation\n",
    "\n",
    "Implement a sliding-window technique and use the trained classifier to search for vehicles in images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc = pickle.load(open(\"saved_svc_YCrCb.p\", \"rb\"))\n",
    "X_scaler = pickle.load(open(\"saved_X_scaler_YCrCb.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_cars(img, \n",
    "              scale, \n",
    "              svc,\n",
    "              X_scaler,\n",
    "              ystart = 400, \n",
    "              ystop = 656, \n",
    "              orient = 8, \n",
    "              pix_per_cell = 8, \n",
    "              cell_per_block = 1, \n",
    "              spatial_size = (32,32), \n",
    "              hist_bins = 32, \n",
    "              cspace = \"YCrCb\", \n",
    "              showImage=True):\n",
    "    \"\"\"\n",
    "    This is a function that can extract features using hog sub-sampling\n",
    "    and make predictions\n",
    "    \"\"\"\n",
    "    # count records the total number of cars detected\n",
    "    count = 0    \n",
    "    draw_img = np.copy(img)\n",
    "    boxes =[]\n",
    "    \n",
    "    img_tosearch = img[ystart:ystop,:,:]\n",
    "    \n",
    "    #ctrans_tosearch = convert_color(img_tosearch, conv='RGB2YCrCb')\n",
    "    if cspace != 'RGB':\n",
    "        if cspace == 'HSV':\n",
    "            ctrans_tosearch = cv2.cvtColor(img_tosearch, cv2.COLOR_RGB2HSV)\n",
    "        elif cspace == 'LUV':\n",
    "            ctrans_tosearch = cv2.cvtColor(img_tosearch, cv2.COLOR_RGB2LUV)\n",
    "        elif cspace == 'HLS':\n",
    "            ctrans_tosearch = cv2.cvtColor(img_tosearch, cv2.COLOR_RGB2HLS)\n",
    "        elif cspace == 'YUV':\n",
    "            ctrans_tosearch = cv2.cvtColor(img_tosearch, cv2.COLOR_RGB2YUV)\n",
    "        elif cspace == 'YCrCb':\n",
    "            ctrans_tosearch = cv2.cvtColor(img_tosearch, cv2.COLOR_RGB2YCrCb)\n",
    "    else: ctrans_tosearch = np.copy(img_tosearch)  \n",
    "                    \n",
    "    if scale != 1:\n",
    "        imshape = ctrans_tosearch.shape\n",
    "        ctrans_tosearch = cv2.resize(ctrans_tosearch, \n",
    "                                     (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\n",
    "        \n",
    "    ch1 = ctrans_tosearch[:,:,0]\n",
    "    ch2 = ctrans_tosearch[:,:,1]\n",
    "    ch3 = ctrans_tosearch[:,:,2]\n",
    "    \n",
    "    # Define blocks and steps as above\n",
    "    nxblocks = (ch1.shape[1] // pix_per_cell)-1\n",
    "    nyblocks = (ch1.shape[0] // pix_per_cell)-1 \n",
    "    nfeat_per_block = orient*cell_per_block**2\n",
    "    # 64 was the orginal sampling rate, with 8 cells and 8 pix per cell\n",
    "    window = 64\n",
    "    nblocks_per_window = (window // pix_per_cell)\n",
    "    \n",
    "    cells_per_step = 2  # Instead of overlap, define how many cells to step\n",
    "    nxsteps = (nxblocks - nblocks_per_window) // cells_per_step\n",
    "    nysteps = (nyblocks - nblocks_per_window) // cells_per_step\n",
    "    \n",
    "    # Compute individual channel HOG features for the entire image\n",
    "    hog1 = get_hog_features(ch1, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog2 = get_hog_features(ch2, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    hog3 = get_hog_features(ch3, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    \n",
    "    for xb in range(nxsteps):\n",
    "        for yb in range(nysteps):\n",
    "            ypos = yb*cells_per_step\n",
    "            xpos = xb*cells_per_step\n",
    "                               \n",
    "            # Extract HOG for this patch\n",
    "            hog_feat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].reshape(1, -1)   \n",
    "            hog_feat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].reshape(1, -1)   \n",
    "            hog_feat3 = hog3[ypos:ypos+nblocks_per_window, xpos:xpos+nblocks_per_window].reshape(1, -1)   \n",
    "            hog_features = np.hstack((hog_feat1, hog_feat2, hog_feat3))\n",
    "\n",
    "            xleft = xpos*pix_per_cell\n",
    "            ytop = ypos*pix_per_cell\n",
    "\n",
    "            test_features = X_scaler.transform(hog_features).reshape(1, -1)   \n",
    "\n",
    "            test_prediction = svc.predict(test_features)\n",
    "\n",
    "            if test_prediction == 1:\n",
    "                xbox_left = np.int(xleft*scale)\n",
    "                ytop_draw = np.int(ytop*scale)\n",
    "                win_draw = np.int(window*scale)\n",
    "                c1 =  np.random.randint(0, 255)\n",
    "                c2 =  np.random.randint(0, 255)\n",
    "                c3 =  np.random.randint(0, 255)\n",
    "                count+=1\n",
    "                if showImage==True:\n",
    "                    cv2.rectangle(draw_img,\n",
    "                                  (xbox_left, ytop_draw+ystart),\n",
    "                                  (xbox_left+win_draw,ytop_draw+win_draw+ystart),\n",
    "                                  (c1,c2,c3),6)              \n",
    "                    cv2.putText(draw_img,\n",
    "                                str( count), \n",
    "                                (int(xbox_left), int(ytop_draw+ystart)), \n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, \n",
    "                                1,(255,255,255), 2,  \n",
    "                                lineType = cv2.LINE_AA)\n",
    "                else:\n",
    "                    if count>0:\n",
    "                        boxes.append(((xbox_left, ytop_draw+ystart),(xbox_left+win_draw,ytop_draw+win_draw+ystart)))\n",
    "\n",
    "    if showImage:\n",
    "        return draw_img, count\n",
    "    else:\n",
    "        return boxes, count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment: my method  of choosing scales\n",
    "\n",
    "**Collect Testing Data**\n",
    "\n",
    "I will not only use the six images from the folder 'test_images'. The testing images and video chuncks are also collected from 'project_video.mp4'. For example, we choose the frames at time 6.5s, 50s, 29s, 30s, 47s, 29.5s. And we cut and save the video between 20s and 26s. \n",
    "\n",
    "Code are as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vidcap = cv2.VideoCapture('project_video.mp4')\n",
    "vidcap.set(cv2.CAP_PROP_POS_MSEC,6500)      # just cue to 6 sec. position\n",
    "success,image = vidcap.read()\n",
    "if success:\n",
    "    cv2.imwrite(\"./test_images/test7.jpg\", image)     # save frame as JPEG file\n",
    "\n",
    "vidcap.set(cv2.CAP_PROP_POS_MSEC,50000)      # just cue to 50 sec. position\n",
    "success,image = vidcap.read()\n",
    "if success:\n",
    "    cv2.imwrite(\"./test_images/test8.jpg\", image)     # save frame as JPEG file\n",
    "\n",
    "#vidcap = cv2.VideoCapture('project_video.mp4')\n",
    "vidcap.set(cv2.CAP_PROP_POS_MSEC,29000)      # just cue to 29 sec. position\n",
    "success,image = vidcap.read()\n",
    "if success:\n",
    "    cv2.imwrite(\"./test_images/test9.jpg\", image)     # save frame as JPEG file\n",
    "\n",
    "#vidcap = cv2.VideoCapture('project_video.mp4')\n",
    "vidcap.set(cv2.CAP_PROP_POS_MSEC,30000)      # just cue to 30 sec. position\n",
    "success,image = vidcap.read()\n",
    "if success:\n",
    "    cv2.imwrite(\"./test_images/test10.jpg\", image)     # save frame as JPEG file\n",
    "\n",
    "#vidcap = cv2.VideoCapture('project_video.mp4')\n",
    "vidcap.set(cv2.CAP_PROP_POS_MSEC,47000)      # just cue to 47 sec. position\n",
    "success,image = vidcap.read()\n",
    "if success:\n",
    "    cv2.imwrite(\"./test_images/test11.jpg\", image)     # save frame as JPEG file\n",
    "\n",
    "#vidcap = cv2.VideoCapture('project_video.mp4')\n",
    "vidcap.set(cv2.CAP_PROP_POS_MSEC,29500)      # just cue to 29.5 sec. position\n",
    "success,image = vidcap.read()\n",
    "if success:\n",
    "    cv2.imwrite(\"./test_images/test12.jpg\", image)     # save frame as JPEG file\n",
    "    #cv2.imshow(\"29sec\",image)\n",
    "    #cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "extract_video = VideoFileClip(\"project_video.mp4\", audio=False).subclip(20,26)\n",
    "%time extract_video.write_videofile(\"test2.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "extract_video = VideoFileClip(\"project_video.mp4\", audio=False).subclip(26,31)\n",
    "%time extract_video.write_videofile(\"test2.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test with all possible scales**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Test the window classifier in one image\n",
    "img = mpimg.imread('test_images/test1.jpg')\n",
    "\n",
    "scales = np.linspace(1.1, 3.4, num=24)\n",
    "plt.figure(figsize=(12,48))\n",
    "row = len(scales) // 2 + 1\n",
    "for i in range(row-1):\n",
    "    plt.subplot(row, 2, 2*i + 1)\n",
    "    scale = scales[2*i]\n",
    "    out_img, count = find_cars(img, \n",
    "                               scale, \n",
    "                               svc, \n",
    "                               X_scaler)\n",
    "    plt.imshow(out_img)\n",
    "    plt.title(\"scale = {}, count = {}\".format(scale, count))\n",
    "    plt.subplot(row, 2, 2*i + 2)\n",
    "    scale = scales[2*i + 1]\n",
    "    out_img, count = find_cars(img, \n",
    "                               scale, \n",
    "                               svc, \n",
    "                               X_scaler)\n",
    "    plt.imshow(out_img)\n",
    "    plt.title(\"scale = {}, count = {}\".format(scale, count))\n",
    "\n",
    "plt.savefig(\"./output_images/scales_test1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread('test_images/test3.jpg')\n",
    "\n",
    "scales = np.linspace(1.1, 3.4, num=24)\n",
    "plt.figure(figsize=(12,48))\n",
    "row = len(scales) // 2 + 1\n",
    "for i in range(row-1):\n",
    "    plt.subplot(row, 2, 2*i + 1)\n",
    "    scale = scales[2*i]\n",
    "    out_img, count = find_cars(img, \n",
    "                           scale, \n",
    "                           svc, \n",
    "                           X_scaler)\n",
    "    plt.imshow(out_img)\n",
    "    plt.title(\"scale = {}, count = {}\".format(scale, count))\n",
    "    plt.subplot(row, 2, 2*i + 2)\n",
    "    scale = scales[2*i + 1]\n",
    "    out_img, count = find_cars(img, \n",
    "                           scale, \n",
    "                           svc, \n",
    "                           X_scaler)\n",
    "    plt.imshow(out_img)\n",
    "    plt.title(\"scale = {}, count = {}\".format(scale, count))\n",
    "    \n",
    "plt.savefig(\"./output_images/scales_test3.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread('test_images/test4.jpg')\n",
    "\n",
    "scales = np.linspace(1.1, 3.4, num=24)\n",
    "plt.figure(figsize=(12,48))\n",
    "row = len(scales) // 2 + 1\n",
    "for i in range(row-1):\n",
    "    plt.subplot(row, 2, 2*i + 1)\n",
    "    scale = scales[2*i]\n",
    "    out_img, count = find_cars(img, \n",
    "                           scale, \n",
    "                           svc, \n",
    "                           X_scaler)\n",
    "    plt.imshow(out_img)\n",
    "    plt.title(\"scale = {}, count = {}\".format(scale, count))\n",
    "    plt.subplot(row, 2, 2*i + 2)\n",
    "    scale = scales[2*i + 1]\n",
    "    out_img, count = find_cars(img, \n",
    "                           scale, \n",
    "                           svc, \n",
    "                           X_scaler)\n",
    "    plt.imshow(out_img)\n",
    "    plt.title(\"scale = {}, count = {}\".format(scale, count))\n",
    "\n",
    "plt.savefig(\"./output_images/scales_test4.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread('test_images/test6.jpg')\n",
    "\n",
    "scales = np.linspace(1.1, 3.4, num=24)\n",
    "plt.figure(figsize=(12,48))\n",
    "row = len(scales) // 2 + 1\n",
    "for i in range(row-1):\n",
    "    plt.subplot(row, 2, 2*i + 1)\n",
    "    scale = scales[2*i]\n",
    "    out_img, count = find_cars(img, \n",
    "                           scale, \n",
    "                           svc, \n",
    "                           X_scaler)\n",
    "    plt.imshow(out_img)\n",
    "    plt.title(\"scale = {}, count = {}\".format(scale, count))\n",
    "    plt.subplot(row, 2, 2*i + 2)\n",
    "    scale = scales[2*i + 1]\n",
    "    out_img, count = find_cars(img, \n",
    "                           scale, \n",
    "                           svc, \n",
    "                           X_scaler)\n",
    "    plt.imshow(out_img)\n",
    "    plt.title(\"scale = {}, count = {}\".format(scale, count))\n",
    "\n",
    "plt.savefig(\"./output_images/scales_test6.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread('test_images/test7.jpg')\n",
    "\n",
    "scales = np.linspace(1.1, 3.4, num=24)\n",
    "plt.figure(figsize=(12,48))\n",
    "row = len(scales) // 2 + 1\n",
    "for i in range(row-1):\n",
    "    plt.subplot(row, 2, 2*i + 1)\n",
    "    scale = scales[2*i]\n",
    "    out_img, count = find_cars(img, \n",
    "                           scale, \n",
    "                           svc, \n",
    "                           X_scaler)\n",
    "    plt.imshow(out_img)\n",
    "    plt.title(\"scale = {}, count = {}\".format(scale, count))\n",
    "    plt.subplot(row, 2, 2*i + 2)\n",
    "    scale = scales[2*i + 1]\n",
    "    out_img, count = find_cars(img, \n",
    "                           scale, \n",
    "                           svc, \n",
    "                           X_scaler)\n",
    "    plt.imshow(out_img)\n",
    "    plt.title(\"scale = {}, count = {}\".format(scale, count))\n",
    "\n",
    "plt.savefig(\"./output_images/scales_test7.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread('test_images/test8.jpg')\n",
    "\n",
    "scales = np.linspace(1.1, 3.4, num=24)\n",
    "plt.figure(figsize=(12,48))\n",
    "row = len(scales) // 2 + 1\n",
    "for i in range(row-1):\n",
    "    plt.subplot(row, 2, 2*i + 1)\n",
    "    scale = scales[2*i]\n",
    "    out_img, count = find_cars(img, \n",
    "                           scale, \n",
    "                           svc, \n",
    "                           X_scaler)\n",
    "    plt.imshow(out_img)\n",
    "    plt.title(\"scale = {}, count = {}\".format(scale, count))\n",
    "    plt.subplot(row, 2, 2*i + 2)\n",
    "    scale = scales[2*i + 1]\n",
    "    out_img, count = find_cars(img, \n",
    "                           scale, \n",
    "                           svc, \n",
    "                           X_scaler)\n",
    "    plt.imshow(out_img)\n",
    "    plt.title(\"scale = {}, count = {}\".format(scale, count))\n",
    "\n",
    "plt.savefig(\"./output_images/scales_test8.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread('test_images/test9.jpg')\n",
    "\n",
    "scales = np.linspace(1.1, 3.4, num=24)\n",
    "plt.figure(figsize=(12,48))\n",
    "row = len(scales) // 2 + 1\n",
    "for i in range(row-1):\n",
    "    plt.subplot(row, 2, 2*i + 1)\n",
    "    scale = scales[2*i]\n",
    "    out_img, count = find_cars(img, \n",
    "                           scale, \n",
    "                           svc, \n",
    "                           X_scaler)\n",
    "    plt.imshow(out_img)\n",
    "    plt.title(\"scale = {}, count = {}\".format(scale, count))\n",
    "    plt.subplot(row, 2, 2*i + 2)\n",
    "    scale = scales[2*i + 1]\n",
    "    out_img, count = find_cars(img, \n",
    "                           scale, \n",
    "                           svc, \n",
    "                           X_scaler)\n",
    "    plt.imshow(out_img)\n",
    "    plt.title(\"scale = {}, count = {}\".format(scale, count))\n",
    "\n",
    "plt.savefig(\"./output_images/scales_test9.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread('test_images/test10.jpg')\n",
    "\n",
    "scales = np.linspace(1.1, 3.4, num=24)\n",
    "plt.figure(figsize=(12,48))\n",
    "row = len(scales) // 2 + 1\n",
    "for i in range(row-1):\n",
    "    plt.subplot(row, 2, 2*i + 1)\n",
    "    scale = scales[2*i]\n",
    "    out_img, count = find_cars(img, \n",
    "                           scale, \n",
    "                           svc, \n",
    "                           X_scaler)\n",
    "    plt.imshow(out_img)\n",
    "    plt.title(\"scale = {}, count = {}\".format(scale, count))\n",
    "    plt.subplot(row, 2, 2*i + 2)\n",
    "    scale = scales[2*i + 1]\n",
    "    out_img, count = find_cars(img, \n",
    "                           scale, \n",
    "                           svc, \n",
    "                           X_scaler)\n",
    "    plt.imshow(out_img)\n",
    "    plt.title(\"scale = {}, count = {}\".format(scale, count))\n",
    "\n",
    "plt.savefig(\"./output_images/scales_test10.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread('test_images/test11.jpg')\n",
    "\n",
    "scales = np.linspace(1.1, 3.4, num=24)\n",
    "plt.figure(figsize=(12,64))\n",
    "row = len(scales) // 2 + 1\n",
    "for i in range(row-1):\n",
    "    plt.subplot(row, 2, 2*i + 1)\n",
    "    scale = scales[2*i]\n",
    "    out_img, count = find_cars(img, \n",
    "                           scale, \n",
    "                           svc, \n",
    "                           X_scaler)\n",
    "    plt.imshow(out_img)\n",
    "    plt.title(\"scale = {}, count = {}\".format(scale, count))\n",
    "    plt.subplot(row, 2, 2*i + 2)\n",
    "    scale = scales[2*i + 1]\n",
    "    out_img, count = find_cars(img, \n",
    "                           scale, \n",
    "                           svc, \n",
    "                           X_scaler)\n",
    "    plt.imshow(out_img)\n",
    "    plt.title(\"scale = {}, count = {}\".format(scale, count))\n",
    "\n",
    "plt.savefig(\"./output_images/scales_test11.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread('test_images/test12.jpg')\n",
    "\n",
    "scales = np.linspace(1.1, 3.4, num=24)\n",
    "plt.figure(figsize=(12,64))\n",
    "row = len(scales) // 2 + 1\n",
    "for i in range(row-1):\n",
    "    plt.subplot(row, 2, 2*i + 1)\n",
    "    scale = scales[2*i]\n",
    "    out_img, count = find_cars(img, \n",
    "                           scale, \n",
    "                           svc, \n",
    "                           X_scaler)\n",
    "    plt.imshow(out_img)\n",
    "    plt.title(\"scale = {}, count = {}\".format(scale, count))\n",
    "    plt.subplot(row, 2, 2*i + 2)\n",
    "    scale = scales[2*i + 1]\n",
    "    out_img, count = find_cars(img, \n",
    "                           scale, \n",
    "                           svc, \n",
    "                           X_scaler)\n",
    "    plt.imshow(out_img)\n",
    "    plt.title(\"scale = {}, count = {}\".format(scale, count))\n",
    "    plt.savefig(\"./output_images/choose_scales2.jpg\")\n",
    "\n",
    "plt.savefig(\"./output_images/scales_test12.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment: Conclusion\n",
    "\n",
    "With above experiments results, one can obtain a table, with columns recording different scales and row corresponding to different testing images. It is not too hard to pick out some 'reasonable' scales for our purpose. Here, I set the scales that will used later as [1.1, 1.4, 1.8, 2.3, 2.6, 2.9]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_cars_multiple(img, \n",
    "                       svc, \n",
    "                       X_scaler,\n",
    "                       ystart = 400, \n",
    "                       ystop = 656, \n",
    "                       orient = 8, \n",
    "                       pix_per_cell = 8, \n",
    "                       cell_per_block = 1, \n",
    "                       spatial_size = (32,32), \n",
    "                       hist_bins = 32, \n",
    "                       cspace = \"YCrCb\"):\n",
    "    scales = [1.1, 1.4, 1.8, 2.3, 2.6, 2.9]\n",
    "    c=0\n",
    "    bbox = []           \n",
    "    for scale in scales:\n",
    "        c += 1\n",
    "        #The first four of scales is valid for the upper half of image\n",
    "        if c < 5:\n",
    "            ystartaux = ystart\n",
    "            ystopaux = int(ystart + (ystop-ystart)*3/4)\n",
    "        else:\n",
    "            ystartaux = int(ystart + (ystop-ystart)/4)\n",
    "            ystopaux = ystop\n",
    "\n",
    "        box, count = find_cars(img = img, \n",
    "                               scale = scale,\n",
    "                               svc = svc,\n",
    "                               X_scaler = X_scaler,\n",
    "                               ystart = ystartaux, \n",
    "                               ystop = ystopaux, \n",
    "                               orient = orient, \n",
    "                               pix_per_cell = pix_per_cell, \n",
    "                               cell_per_block = cell_per_block, \n",
    "                               spatial_size = spatial_size, \n",
    "                               hist_bins = hist_bins, \n",
    "                               cspace = cspace, \n",
    "                               showImage = False)\n",
    "        if count>0:\n",
    "            for b in box:\n",
    "                bbox.append(b)\n",
    "    return bbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heat Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_heat(heatmap, bbox_list):\n",
    "    # Iterate through list of bboxes\n",
    "    for box in bbox_list:\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "    # Return updated heatmap\n",
    "    return heatmap # Iterate through list of bboxes\n",
    "    \n",
    "def apply_threshold(heatmap, threshold):\n",
    "    # Zero out pixels below the threshold\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    # Return thresholded map\n",
    "    return heatmap\n",
    "\n",
    "def draw_labeled_bboxes(labels, heatmap,img=None):\n",
    "    # Iterate through all detected cars\n",
    "    b_heat=[] #((x1,y1),(x2,y2))\n",
    "\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        highv = np.sum(heatmap[np.min(nonzeroy):np.max(nonzeroy), np.min(nonzerox):np.max(nonzerox)])\n",
    "        # Draw the box on the image\n",
    "        if not img is None:\n",
    "            cv2.rectangle(img, bbox[0], bbox[1], (0,0,200), 3)\n",
    "        \n",
    "        b_heat.append(((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy))))\n",
    "\n",
    "    # Return the image\n",
    "    if not img is None:\n",
    "        return img,b_heat\n",
    "    else:\n",
    "        return b_heat\n",
    "\n",
    "def heatmap(image, box_list, threshold=1, showImg = True):\n",
    "    \n",
    "    heat = np.zeros_like(image[:,:,0]).astype(np.float)\n",
    "    # Add heat to each box in box list\n",
    "    heat = add_heat(heat,box_list)\n",
    "\n",
    "    # Apply threshold to help remove false positives\n",
    "    heat = apply_threshold(heat,threshold)\n",
    "\n",
    "    # Visualize the heatmap when displaying    \n",
    "    heatmap = np.clip(heat, 0, 255)\n",
    "\n",
    "    # Find final boxes from heatmap using label function\n",
    "    labels = label(heatmap)\n",
    "    \n",
    "    if showImg ==  True:\n",
    "        draw_img,lbl_heat = draw_labeled_bboxes(labels, heatmap, np.copy(image))\n",
    "        return draw_img, heatmap, lbl_heat\n",
    "    else:\n",
    "        lbl_heat = draw_labeled_bboxes(labels,heatmap)\n",
    "        return heatmap, lbl_heat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = mpimg.imread('./test_images/test1.jpg')\n",
    "\n",
    "box_list = find_cars_multiple(img = image, \n",
    "                           svc = svc,\n",
    "                           X_scaler = X_scaler,\n",
    "                           ystart = 400, \n",
    "                           ystop = 656, \n",
    "                           orient = 8, \n",
    "                           pix_per_cell = 8, \n",
    "                           cell_per_block = 1, \n",
    "                           spatial_size = (32,32), \n",
    "                           hist_bins = 32, \n",
    "                           cspace = \"YCrCb\") \n",
    "\n",
    "thres = 1\n",
    "draw_img, heat_map, lbl_heat = heatmap(image, box_list, thres, True)\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "plt.subplot(121)\n",
    "plt.imshow(draw_img)\n",
    "plt.title('Car Positions')\n",
    "plt.subplot(122)\n",
    "plt.imshow(heat_map, cmap='hot')\n",
    "plt.title('Heat Map')\n",
    "\n",
    "plt.savefig(\"./output_images/heatmap1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image = mpimg.imread('./test_images/test12.jpg')\n",
    "\n",
    "box_list = find_cars_multiple(img = image, \n",
    "                           svc = svc,\n",
    "                           X_scaler = X_scaler,\n",
    "                           ystart = 400, \n",
    "                           ystop = 656, \n",
    "                           orient = 8, \n",
    "                           pix_per_cell = 8, \n",
    "                           cell_per_block = 1, \n",
    "                           spatial_size = (32,32), \n",
    "                           hist_bins = 32, \n",
    "                           cspace = \"YCrCb\") \n",
    "\n",
    "thres = 1\n",
    "draw_img, heat_map, lbl_heat = heatmap(image, box_list, thres, True)\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "plt.subplot(121)\n",
    "plt.imshow(draw_img)\n",
    "plt.title('Car Positions')\n",
    "plt.subplot(122)\n",
    "plt.imshow(heat_map, cmap='hot')\n",
    "plt.title('Heat Map')\n",
    "\n",
    "plt.savefig(\"./output_images/heatmap12.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image = mpimg.imread('./test_images/test5.jpg')\n",
    "\n",
    "box_list = find_cars_multiple(img = image, \n",
    "                           svc = svc,\n",
    "                           X_scaler = X_scaler,\n",
    "                           ystart = 400, \n",
    "                           ystop = 656, \n",
    "                           orient = 8, \n",
    "                           pix_per_cell = 8, \n",
    "                           cell_per_block = 1, \n",
    "                           spatial_size = (32,32), \n",
    "                           hist_bins = 32, \n",
    "                           cspace = \"YCrCb\") \n",
    "\n",
    "thres = 1\n",
    "draw_img, heat_map, lbl_heat = heatmap(image, box_list, thres, True)\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "plt.subplot(121)\n",
    "plt.imshow(draw_img)\n",
    "plt.title('Car Positions')\n",
    "plt.subplot(122)\n",
    "plt.imshow(heat_map, cmap='hot')\n",
    "plt.title('Heat Map')\n",
    "plt.savefig(\"./output_images/heatmap5.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svc = pickle.load(open(\"saved_svc_YCrCb.p\", \"rb\")) \n",
    "X_scaler = pickle.load(open(\"saved_X_scaler_YCrCb.p\", \"rb\")) \n",
    "ystart = 400\n",
    "ystop = 656\n",
    "orient = 8 \n",
    "pix_per_cell = 8 \n",
    "cell_per_block = 1 \n",
    "spatial_size = (32, 32) \n",
    "hist_bins = 32 \n",
    "cspace = 'YCrCb'\n",
    "\n",
    "\n",
    "nframes = 10\n",
    "smooth_thres = 2\n",
    "smooth_average= 6\n",
    "bbox_frames =[]\n",
    "#Initialization of list\n",
    "for i in range(nframes):\n",
    "    bbox_frames.append(0)\n",
    "counter = 0\n",
    "\n",
    "def process_image(img):\n",
    "    \n",
    "    global counter\n",
    "    global bbox_frames\n",
    "    \n",
    "    counter += 1\n",
    "    countFrame = counter % nframes\n",
    "    \n",
    "    #Find rectangles for one image\n",
    "    bbox1 = find_cars_multiple(img = img, \n",
    "                               svc = svc,\n",
    "                               X_scaler = X_scaler,\n",
    "                               ystart = ystart,  \n",
    "                               ystop = ystop, \n",
    "                               orient = orient, \n",
    "                               pix_per_cell = pix_per_cell, \n",
    "                               cell_per_block = cell_per_block, \n",
    "                               spatial_size = spatial_size, \n",
    "                               hist_bins = hist_bins, \n",
    "                               cspace = cspace)\n",
    "\n",
    "    # Find heatmap single image\n",
    "    thres = smooth_thres\n",
    "    heat, bboxHeat = heatmap(img, bbox1, thres, False)\n",
    "    #dimg, heat, bboxHeat = heatmap(img, bbox1, thres, True)\n",
    "\n",
    "\n",
    "    # Store the rectangles of the frame\n",
    "    bbox_frames[countFrame] = bboxHeat\n",
    "    \n",
    "    # Sum rectangles of the nframes\n",
    "    bbox2 = []\n",
    "    for box in bbox_frames:\n",
    "        if box != 0:\n",
    "            for b in box:\n",
    "                bbox2.append(b)\n",
    "                \n",
    "    # Find heatmap of average\n",
    "    thres = smooth_average\n",
    "    dimg, heat, bboxHeat2 = heatmap(img, bbox2, thres, True)    \n",
    "\n",
    "    return dimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "image = mpimg.imread('test_images/test6.jpg')\n",
    "\n",
    "plt.figure(figsize=(25,10))\n",
    "nframes = 1\n",
    "smooth_thres = 1\n",
    "smooth_average = 0\n",
    "bbox_frames=[]\n",
    "#Inicialization of list\n",
    "for i in range(nframes):\n",
    "    bbox_frames.append(0)\n",
    "counter = 0\n",
    "\n",
    "img2 = process_image(image)\n",
    "plt.imshow(img2)\n",
    "plt.savefig(\"./output_images/pipeline1.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "#from IPython.display import HTML\n",
    "#import moviepy as mve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counter = 0\n",
    "nframes = 26\n",
    "smooth_thres = 1\n",
    "smooth_average = 5\n",
    "\n",
    "bbox_frames=[]\n",
    "#Inicialization of list\n",
    "for i in range(nframes):\n",
    "    bbox_frames.append(0)\n",
    "counter = 0\n",
    "\n",
    "output = 'output_test2.mp4'\n",
    "clip1 = VideoFileClip(\"test2.mp4\", audio=False)\n",
    "\n",
    "out_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time out_clip.write_videofile(output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Create video file pipeline\n",
    "counter = 0\n",
    "nframes = 26\n",
    "smooth_thres = 1\n",
    "smooth_average = 5\n",
    "\n",
    "bbox_frames=[]\n",
    "#Inicialization of list\n",
    "for i in range(nframes):\n",
    "    bbox_frames.append(0)\n",
    "counter = 0\n",
    "\n",
    "output = 'output_project_video.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\", audio=False)\n",
    "\n",
    "out_clip = clip1.fl_image(process_image) #NOTE: this function expects color images!!\n",
    "%time out_clip.write_videofile(output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
